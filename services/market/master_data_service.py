import urllib.request
import ssl
import zipfile
import os
import pandas as pd
from utils.logger import get_logger

logger = get_logger("master_data_service")

class MasterDataService:
    BASE_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "data", "master")

    @classmethod
    def _ensure_dir(cls):
        os.makedirs(cls.BASE_DIR, exist_ok=True)

    @classmethod
    def download_master_files(cls):
        """KOSPI, KOSDAQ ë§ˆìŠ¤í„° íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì••ì¶•ì„ í’‰ë‹ˆë‹¤."""
        cls._ensure_dir()
        ssl._create_default_https_context = ssl._create_unverified_context

        targets = {
            "KOSPI": ("https://new.real.download.dws.co.kr/common/master/kospi_code.mst.zip", "kospi_code.zip"),
            "KOSDAQ": ("https://new.real.download.dws.co.kr/common/master/kosdaq_code.mst.zip", "kosdaq_code.zip")
        }

        for market, (url, zip_name) in targets.items():
            zip_path = os.path.join(cls.BASE_DIR, zip_name)
            logger.info(f"ğŸ“¥ Downloading {market} master zip from {url}...")
            urllib.request.urlretrieve(url, zip_path)

            with zipfile.ZipFile(zip_path) as z:
                z.extractall(cls.BASE_DIR)
            
            os.remove(zip_path)
            logger.info(f"âœ… {market} master file extracted.")

    @classmethod
    def get_kospi_master(cls):
        file_path = os.path.join(cls.BASE_DIR, "kospi_code.mst")
        if not os.path.exists(file_path):
            cls.download_master_files()

        tmp1 = os.path.join(cls.BASE_DIR, "kospi_part1.tmp")
        tmp2 = os.path.join(cls.BASE_DIR, "kospi_part2.tmp")

        with open(file_path, mode="r", encoding="cp949") as f, open(tmp1, "w") as wf1, open(tmp2, "w") as wf2:
            for row in f:
                rf1 = row[0:len(row) - 228]
                rf1_1 = rf1[0:9].rstrip()
                rf1_3 = rf1[21:].strip()
                wf1.write(f"{rf1_1},{rf1_3}\n")
                wf2.write(row[-228:])

        df1 = pd.read_csv(tmp1, header=None, names=['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…'], encoding='utf-8')
        field_specs = [2, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 5, 5, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 3, 1, 3, 12, 12, 8, 15, 21, 2, 7, 1, 1, 1, 1, 1, 9, 9, 9, 5, 9, 8, 9, 3, 1, 1, 1]
        part2_columns = ['ê·¸ë£¹ì½”ë“œ', 'ì‹œê°€ì´ì•¡ê·œëª¨', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì¤‘ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì†Œë¶„ë¥˜', 'ì œì¡°ì—…', 'ì €ìœ ë™ì„±', 'ì§€ë°°êµ¬ì¡°ì§€ìˆ˜ì¢…ëª©', 'KOSPI200ì„¹í„°ì—…ì¢…', 'KOSPI100', 'KOSPI50', 'KRX', 'ETP', 'ELWë°œí–‰', 'KRX100', 'KRXìë™ì°¨', 'KRXë°˜ë„ì²´', 'KRXë°”ì´ì˜¤', 'KRXì€í–‰', 'SPAC', 'KRXì—ë„ˆì§€í™”í•™', 'KRXì² ê°•', 'ë‹¨ê¸°ê³¼ì—´', 'KRXë¯¸ë””ì–´í†µì‹ ', 'KRXê±´ì„¤', 'Non1', 'KRXì¦ê¶Œ', 'KRXì„ ë°•', 'KRXì„¹í„°_ë³´í—˜', 'KRXì„¹í„°_ìš´ì†¡', 'SRI', 'ê¸°ì¤€ê°€', 'ë§¤ë§¤ìˆ˜ëŸ‰ë‹¨ìœ„', 'ì‹œê°„ì™¸ìˆ˜ëŸ‰ë‹¨ìœ„', 'ê±°ë˜ì •ì§€', 'ì •ë¦¬ë§¤ë§¤', 'ê´€ë¦¬ì¢…ëª©', 'ì‹œì¥ê²½ê³ ', 'ê²½ê³ ì˜ˆê³ ', 'ë¶ˆì„±ì‹¤ê³µì‹œ', 'ìš°íšŒìƒì¥', 'ë½êµ¬ë¶„', 'ì•¡ë©´ë³€ê²½', 'ì¦ìêµ¬ë¶„', 'ì¦ê±°ê¸ˆë¹„ìœ¨', 'ì‹ ìš©ê°€ëŠ¥', 'ì‹ ìš©ê¸°ê°„', 'ì „ì¼ê±°ë˜ëŸ‰', 'ì•¡ë©´ê°€', 'ìƒì¥ì¼ì', 'ìƒì¥ì£¼ìˆ˜', 'ìë³¸ê¸ˆ', 'ê²°ì‚°ì›”', 'ê³µëª¨ê°€', 'ìš°ì„ ì£¼', 'ê³µë§¤ë„ê³¼ì—´', 'ì´ìƒê¸‰ë“±', 'KRX300', 'KOSPI', 'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ê²½ìƒì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ROE', 'ê¸°ì¤€ë…„ì›”', 'ì‹œê°€ì´ì•¡', 'ê·¸ë£¹ì‚¬ì½”ë“œ', 'íšŒì‚¬ì‹ ìš©í•œë„ì´ˆê³¼', 'ë‹´ë³´ëŒ€ì¶œê°€ëŠ¥', 'ëŒ€ì£¼ê°€ëŠ¥']
        df2 = pd.read_fwf(tmp2, widths=field_specs, names=part2_columns)
        
        df = pd.concat([df1.reset_index(drop=True), df2.reset_index(drop=True)], axis=1)
        os.remove(tmp1)
        os.remove(tmp2)
        return df

    @classmethod
    def get_kosdaq_master(cls):
        file_path = os.path.join(cls.BASE_DIR, "kosdaq_code.mst")
        if not os.path.exists(file_path):
            cls.download_master_files()

        tmp1 = os.path.join(cls.BASE_DIR, "kosdaq_part1.tmp")
        tmp2 = os.path.join(cls.BASE_DIR, "kosdaq_part2.tmp")

        with open(file_path, mode="r", encoding="cp949") as f, open(tmp1, "w") as wf1, open(tmp2, "w") as wf2:
            for row in f:
                rf1 = row[0:len(row) - 222]
                rf1_1 = rf1[0:9].rstrip()
                rf1_3 = rf1[21:].strip()
                wf1.write(f"{rf1_1},{rf1_3}\n")
                wf2.write(row[-222:])

        df1 = pd.read_csv(tmp1, header=None, names=['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…'], encoding='utf-8')
        field_specs = [2, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 5, 5, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 3, 1, 3, 12, 12, 8, 15, 21, 2, 7, 1, 1, 1, 1, 9, 9, 9, 5, 9, 8, 9, 3, 1, 1, 1]
        part2_columns = ['ì¦ê¶Œê·¸ë£¹êµ¬ë¶„ì½”ë“œ','ì‹œê°€ì´ì•¡ê·œëª¨','ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜','ì§€ìˆ˜ì—…ì¢…ì¤‘ë¶„ë¥˜','ì§€ìˆ˜ì—…ì¢…ì†Œë¶„ë¥˜','ë²¤ì²˜ê¸°ì—…','ì €ìœ ë™ì„±','KRXì¢…ëª©','ETP','KRX100','KRXìë™ì°¨','KRXë°˜ë„ì²´','KRXë°”ì´ì˜¤','KRXì€í–‰','SPAC','KRXì—ë„ˆì§€í™”í•™','KRXì² ê°•','ë‹¨ê¸°ê³¼ì—´','KRXë¯¸ë””ì–´í†µì‹ ','KRXê±´ì„¤','íˆ¬ìì£¼ì˜í™˜ê¸°ì¢…ëª©','KRXì¦ê¶Œ','KRXì„ ë°•','KRXë³´í—˜','KRXìš´ì†¡','KOSDAQ150','ê¸°ì¤€ê°€','ì •ê·œë§¤ë§¤ë‹¨ìœ„','ì‹œê°„ì™¸ë§¤ë§¤ë‹¨ìœ„','ê±°ë˜ì •ì§€','ì •ë¦¬ë§¤ë§¤','ê´€ë¦¬ì¢…ëª©','ì‹œì¥ê²½ê³ ','ê²½ê³ ì˜ˆê³ ','ë¶ˆì„±ì‹¤ê³µì‹œ','ìš°íšŒìƒì¥','ë½êµ¬ë¶„','ì•¡ë©´ë³€ê²½','ì¦ìêµ¬ë¶„','ì¦ê±°ê¸ˆë¹„ìœ¨','ì‹ ìš©ê°€ëŠ¥','ì‹ ìš©ê¸°ê°„','ì „ì¼ê±°ë˜ëŸ‰','ì•¡ë©´ê°€','ìƒì¥ì¼ì','ìƒì¥ì£¼ìˆ˜','ìë³¸ê¸ˆ','ê²°ì‚°ì›”','ê³µëª¨ê°€','ìš°ì„ ì£¼','ê³µë§¤ë„ê³¼ì—´','ì´ìƒê¸‰ë“±','KRX300','ë§¤ì¶œì•¡','ì˜ì—…ì´ìµ','ê²½ìƒì´ìµ','ë‹¹ê¸°ìˆœì´ìµ','ROE','ê¸°ì¤€ë…„ì›”','ì „ì¼ê¸°ì¤€ ì‹œê°€ì´ì•¡ (ì–µ)','ê·¸ë£¹ì‚¬ì½”ë“œ','íšŒì‚¬ì‹ ìš©í•œë„ì´ˆê³¼','ë‹´ë³´ëŒ€ì¶œê°€ëŠ¥','ëŒ€ì£¼ê°€ëŠ¥']
        df2 = pd.read_fwf(tmp2, widths=field_specs, names=part2_columns)

        df = pd.concat([df1.reset_index(drop=True), df2.reset_index(drop=True)], axis=1)
        os.remove(tmp1)
        os.remove(tmp2)
        return df

    @classmethod
    def get_top_market_cap_tickers(cls, count: int = 100) -> list:
        """ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ í•©ì‚° ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            kospi = cls.get_kospi_master()
            kosdaq = cls.get_kosdaq_master()
            
            # ì‹œê°€ì´ì•¡ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ countê°œ ì¶”ì¶œ
            # KOSPI: 'ì‹œê°€ì´ì•¡' (ë‹¨ìœ„: ì–µ)
            # KOSDAQ: 'ì‹œê°€ì´ì•¡' (ë‹¨ìœ„: ì–µ)
            kospi_df = kospi[['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…', 'ì‹œê°€ì´ì•¡']].rename(columns={'ì‹œê°€ì´ì•¡': 'market_cap_raw'})
            kosdaq_df = kosdaq[['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…', 'ì „ì¼ê¸°ì¤€ ì‹œê°€ì´ì•¡ (ì–µ)']].rename(columns={'ì „ì¼ê¸°ì¤€ ì‹œê°€ì´ì•¡ (ì–µ)': 'market_cap_raw'})
            
            merged = pd.concat([kospi_df, kosdaq_df])
            merged['market_cap_raw'] = pd.to_numeric(merged['market_cap_raw'], errors='coerce').fillna(0)
            top_stocks = merged.sort_values(by='market_cap_raw', ascending=False).head(count)
            
            result = []
            for _, row in top_stocks.iterrows():
                result.append({
                    "mksc_shrn_iscd": row['ë‹¨ì¶•ì½”ë“œ'],
                    "hts_kor_isnm": row['í•œê¸€ëª…'],
                    "stck_prpr": "0", # ë§ˆìŠ¤í„°ì—ëŠ” í˜„ì¬ê°€ ì—†ìŒ (ë­í‚¹ API ê·œê²© ë§ì¶¤ìš©)
                    "data_rank": "0" 
                })
            
            logger.info(f"ğŸ† Local Ranking created: {len(result)} stocks selected.")
            return result
        except Exception as e:
            logger.error(f"âŒ Error creating local ranking: {e}")
            return []
