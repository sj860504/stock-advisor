"""KOSPI/KOSDAQ ë§ˆìŠ¤í„° íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìƒì„±."""
import os
import ssl
import urllib.request
import zipfile
from typing import List

import pandas as pd

from utils.logger import get_logger

logger = get_logger("master_data_service")

# ë‹¤ìš´ë¡œë“œ URL ë° ë¡œì»¬ íŒŒì¼ëª…
MASTER_DOWNLOAD_TARGETS = {
    "KOSPI": (
        "https://new.real.download.dws.co.kr/common/master/kospi_code.mst.zip",
        "kospi_code.zip",
    ),
    "KOSDAQ": (
        "https://new.real.download.dws.co.kr/common/master/kosdaq_code.mst.zip",
        "kosdaq_code.zip",
    ),
}
DEFAULT_TOP_COUNT = 100


class MasterDataService:
    """KOSPI/KOSDAQ ë§ˆìŠ¤í„° íŒŒì¼ ë‹¤ìš´ë¡œë“œÂ·íŒŒì‹± ë° ì‹œì´ ìƒìœ„ ì¢…ëª© ì¡°íšŒ."""

    BASE_DIR = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
        "data",
        "master",
    )

    @classmethod
    def _ensure_dir(cls) -> None:
        os.makedirs(cls.BASE_DIR, exist_ok=True)

    @classmethod
    def download_master_files(cls) -> None:
        """KOSPI, KOSDAQ ë§ˆìŠ¤í„° ZIPì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì••ì¶• í•´ì œí•©ë‹ˆë‹¤."""
        cls._ensure_dir()
        ssl._create_default_https_context = ssl._create_unverified_context
        for market, (url, zip_name) in MASTER_DOWNLOAD_TARGETS.items():
            zip_path = os.path.join(cls.BASE_DIR, zip_name)
            logger.info(f"ğŸ“¥ Downloading {market} master zip from {url}...")
            urllib.request.urlretrieve(url, zip_path)
            with zipfile.ZipFile(zip_path) as zf:
                zf.extractall(cls.BASE_DIR)
            os.remove(zip_path)
            logger.info(f"âœ… {market} master file extracted.")

    @classmethod
    def get_kospi_master(cls):
        file_path = os.path.join(cls.BASE_DIR, "kospi_code.mst")
        if not os.path.exists(file_path):
            cls.download_master_files()

        tmp1 = os.path.join(cls.BASE_DIR, "kospi_part1.tmp")
        tmp2 = os.path.join(cls.BASE_DIR, "kospi_part2.tmp")

        with open(file_path, mode="r", encoding="cp949") as f, open(tmp1, "w") as wf1, open(tmp2, "w") as wf2:
            for row in f:
                rf1 = row[0:len(row) - 228]
                rf1_1 = rf1[0:9].rstrip()
                rf1_3 = rf1[21:].strip()
                wf1.write(f"{rf1_1},{rf1_3}\n")
                wf2.write(row[-228:])

        df1 = pd.read_csv(tmp1, header=None, names=['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…'], encoding='utf-8')
        field_specs = [2, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 5, 5, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 3, 1, 3, 12, 12, 8, 15, 21, 2, 7, 1, 1, 1, 1, 1, 9, 9, 9, 5, 9, 8, 9, 3, 1, 1, 1]
        part2_columns = ['ê·¸ë£¹ì½”ë“œ', 'ì‹œê°€ì´ì•¡ê·œëª¨', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì¤‘ë¶„ë¥˜', 'ì§€ìˆ˜ì—…ì¢…ì†Œë¶„ë¥˜', 'ì œì¡°ì—…', 'ì €ìœ ë™ì„±', 'ì§€ë°°êµ¬ì¡°ì§€ìˆ˜ì¢…ëª©', 'KOSPI200ì„¹í„°ì—…ì¢…', 'KOSPI100', 'KOSPI50', 'KRX', 'ETP', 'ELWë°œí–‰', 'KRX100', 'KRXìë™ì°¨', 'KRXë°˜ë„ì²´', 'KRXë°”ì´ì˜¤', 'KRXì€í–‰', 'SPAC', 'KRXì—ë„ˆì§€í™”í•™', 'KRXì² ê°•', 'ë‹¨ê¸°ê³¼ì—´', 'KRXë¯¸ë””ì–´í†µì‹ ', 'KRXê±´ì„¤', 'Non1', 'KRXì¦ê¶Œ', 'KRXì„ ë°•', 'KRXì„¹í„°_ë³´í—˜', 'KRXì„¹í„°_ìš´ì†¡', 'SRI', 'ê¸°ì¤€ê°€', 'ë§¤ë§¤ìˆ˜ëŸ‰ë‹¨ìœ„', 'ì‹œê°„ì™¸ìˆ˜ëŸ‰ë‹¨ìœ„', 'ê±°ë˜ì •ì§€', 'ì •ë¦¬ë§¤ë§¤', 'ê´€ë¦¬ì¢…ëª©', 'ì‹œì¥ê²½ê³ ', 'ê²½ê³ ì˜ˆê³ ', 'ë¶ˆì„±ì‹¤ê³µì‹œ', 'ìš°íšŒìƒì¥', 'ë½êµ¬ë¶„', 'ì•¡ë©´ë³€ê²½', 'ì¦ìêµ¬ë¶„', 'ì¦ê±°ê¸ˆë¹„ìœ¨', 'ì‹ ìš©ê°€ëŠ¥', 'ì‹ ìš©ê¸°ê°„', 'ì „ì¼ê±°ë˜ëŸ‰', 'ì•¡ë©´ê°€', 'ìƒì¥ì¼ì', 'ìƒì¥ì£¼ìˆ˜', 'ìë³¸ê¸ˆ', 'ê²°ì‚°ì›”', 'ê³µëª¨ê°€', 'ìš°ì„ ì£¼', 'ê³µë§¤ë„ê³¼ì—´', 'ì´ìƒê¸‰ë“±', 'KRX300', 'KOSPI', 'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ê²½ìƒì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ROE', 'ê¸°ì¤€ë…„ì›”', 'ì‹œê°€ì´ì•¡', 'ê·¸ë£¹ì‚¬ì½”ë“œ', 'íšŒì‚¬ì‹ ìš©í•œë„ì´ˆê³¼', 'ë‹´ë³´ëŒ€ì¶œê°€ëŠ¥', 'ëŒ€ì£¼ê°€ëŠ¥']
        df2 = pd.read_fwf(tmp2, widths=field_specs, names=part2_columns)
        
        df = pd.concat([df1.reset_index(drop=True), df2.reset_index(drop=True)], axis=1)
        os.remove(tmp1)
        os.remove(tmp2)
        return df

    @classmethod
    def get_kosdaq_master(cls):
        file_path = os.path.join(cls.BASE_DIR, "kosdaq_code.mst")
        if not os.path.exists(file_path):
            cls.download_master_files()

        tmp1 = os.path.join(cls.BASE_DIR, "kosdaq_part1.tmp")
        tmp2 = os.path.join(cls.BASE_DIR, "kosdaq_part2.tmp")

        with open(file_path, mode="r", encoding="cp949") as f, open(tmp1, "w") as wf1, open(tmp2, "w") as wf2:
            for row in f:
                rf1 = row[0:len(row) - 222]
                rf1_1 = rf1[0:9].rstrip()
                rf1_3 = rf1[21:].strip()
                wf1.write(f"{rf1_1},{rf1_3}\n")
                wf2.write(row[-222:])

        df1 = pd.read_csv(tmp1, header=None, names=['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…'], encoding='utf-8')
        field_specs = [2, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 5, 5, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 3, 1, 3, 12, 12, 8, 15, 21, 2, 7, 1, 1, 1, 1, 9, 9, 9, 5, 9, 8, 9, 3, 1, 1, 1]
        part2_columns = ['ì¦ê¶Œê·¸ë£¹êµ¬ë¶„ì½”ë“œ','ì‹œê°€ì´ì•¡ê·œëª¨','ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜','ì§€ìˆ˜ì—…ì¢…ì¤‘ë¶„ë¥˜','ì§€ìˆ˜ì—…ì¢…ì†Œë¶„ë¥˜','ë²¤ì²˜ê¸°ì—…','ì €ìœ ë™ì„±','KRXì¢…ëª©','ETP','KRX100','KRXìë™ì°¨','KRXë°˜ë„ì²´','KRXë°”ì´ì˜¤','KRXì€í–‰','SPAC','KRXì—ë„ˆì§€í™”í•™','KRXì² ê°•','ë‹¨ê¸°ê³¼ì—´','KRXë¯¸ë””ì–´í†µì‹ ','KRXê±´ì„¤','íˆ¬ìì£¼ì˜í™˜ê¸°ì¢…ëª©','KRXì¦ê¶Œ','KRXì„ ë°•','KRXë³´í—˜','KRXìš´ì†¡','KOSDAQ150','ê¸°ì¤€ê°€','ì •ê·œë§¤ë§¤ë‹¨ìœ„','ì‹œê°„ì™¸ë§¤ë§¤ë‹¨ìœ„','ê±°ë˜ì •ì§€','ì •ë¦¬ë§¤ë§¤','ê´€ë¦¬ì¢…ëª©','ì‹œì¥ê²½ê³ ','ê²½ê³ ì˜ˆê³ ','ë¶ˆì„±ì‹¤ê³µì‹œ','ìš°íšŒìƒì¥','ë½êµ¬ë¶„','ì•¡ë©´ë³€ê²½','ì¦ìêµ¬ë¶„','ì¦ê±°ê¸ˆë¹„ìœ¨','ì‹ ìš©ê°€ëŠ¥','ì‹ ìš©ê¸°ê°„','ì „ì¼ê±°ë˜ëŸ‰','ì•¡ë©´ê°€','ìƒì¥ì¼ì','ìƒì¥ì£¼ìˆ˜','ìë³¸ê¸ˆ','ê²°ì‚°ì›”','ê³µëª¨ê°€','ìš°ì„ ì£¼','ê³µë§¤ë„ê³¼ì—´','ì´ìƒê¸‰ë“±','KRX300','ë§¤ì¶œì•¡','ì˜ì—…ì´ìµ','ê²½ìƒì´ìµ','ë‹¹ê¸°ìˆœì´ìµ','ROE','ê¸°ì¤€ë…„ì›”','ì „ì¼ê¸°ì¤€ ì‹œê°€ì´ì•¡ (ì–µ)','ê·¸ë£¹ì‚¬ì½”ë“œ','íšŒì‚¬ì‹ ìš©í•œë„ì´ˆê³¼','ë‹´ë³´ëŒ€ì¶œê°€ëŠ¥','ëŒ€ì£¼ê°€ëŠ¥']
        df2 = pd.read_fwf(tmp2, widths=field_specs, names=part2_columns)

        df = pd.concat([df1.reset_index(drop=True), df2.reset_index(drop=True)], axis=1)
        os.remove(tmp1)
        os.remove(tmp2)
        return df

    @classmethod
    def get_top_market_cap_tickers(cls, count: int = DEFAULT_TOP_COUNT) -> List[dict]:
        """ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ í•©ì‚° ì‹œê°€ì´ì•¡ ìƒìœ„ countê°œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ë­í‚¹ API ê·œê²© í˜¸í™˜)"""
        try:
            kospi = cls.get_kospi_master()
            kosdaq = cls.get_kosdaq_master()
            kospi_df = kospi[["ë‹¨ì¶•ì½”ë“œ", "í•œê¸€ëª…", "ì‹œê°€ì´ì•¡"]].rename(columns={"ì‹œê°€ì´ì•¡": "market_cap_raw"})
            kosdaq_df = kosdaq[["ë‹¨ì¶•ì½”ë“œ", "í•œê¸€ëª…", "ì „ì¼ê¸°ì¤€ ì‹œê°€ì´ì•¡ (ì–µ)"]].rename(
                columns={"ì „ì¼ê¸°ì¤€ ì‹œê°€ì´ì•¡ (ì–µ)": "market_cap_raw"}
            )
            merged = pd.concat([kospi_df, kosdaq_df])
            merged["market_cap_raw"] = pd.to_numeric(merged["market_cap_raw"], errors="coerce").fillna(0)
            top_stocks = merged.sort_values(by="market_cap_raw", ascending=False).head(count)
            result = [
                {
                    "mksc_shrn_iscd": row["ë‹¨ì¶•ì½”ë“œ"],
                    "hts_kor_isnm": row["í•œê¸€ëª…"],
                    "stck_prpr": "0",
                    "data_rank": "0",
                }
                for _, row in top_stocks.iterrows()
            ]
            logger.info(f"ğŸ† Local Ranking created: {len(result)} stocks selected.")
            return result
        except Exception as e:
            logger.error(f"âŒ Error creating local ranking: {e}")
            return []
